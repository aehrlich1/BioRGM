batch_size: 32
dim_h: 128 # should be inferred from pretrain model
datasets: ["BACE", "BBBP"] # ["BACE", "BBBP"]
dropout: 0.1
epochs: 10
freeze_pretrain: [True] # True | False
lr: 0.0005
pretrain_models:
  - "curious-armadillo-45" # null | <model_name>
runs: 2 # How often to repeat the run
task: "finetune"